import os
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
from timm import create_model
from tqdm import tqdm
import kagglehub
import matplotlib.pyplot as plt

# ----- ë°ì´í„° ë‹¤ìš´ë¡œë“œ -----
DATA_PATH = kagglehub.dataset_download("arnaud58/flickrfaceshq-dataset-ffhq")
print('Dataset path:", DATA_PATH)

# ----- í•˜ì´í¼íŒŒë¼ë¯¸í„° í›„ë³´ -----
param_grid = [
    {"BATCH_SIZE": 16, "LR": 3e-4, "EPOCHS": 8},
    {"BATCH_SIZE": 32, "LR": 1e-4, "EPOCHS": 10},
    {"BATCH_SIZE": 64, "LR": 5e-5, "EPOCHS": 12},
]

# ----- ì„¤ì • -----
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
IMG_SIZE = 224
NUM_WORKERS = 4
MODEL_PATH = "best_vit_b32_ffhq.pth"

# ----- ë°ì´í„° ì „ì²˜ë¦¬ -----
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)
])

# ----- ë°ì´í„°ì…‹ ë¡œë“œ -----
train_dataset = datasets.ImageFolder(os.path.join(DATA_PATH, 'train'), transform=transform)
val_dataset = datasets.ImageFolder(os.path.join(DATA_PATH, 'val'), transform=transform)

train_classes = train_dataset.classes
NUM_CLASSES = len(train_classes)
print(f' Detected classes: {train_classes}")

# ----- í‰ê°€ í•¨ìˆ˜ -----
def evaluate(model, loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return 100 * correct / total

# ----- ìµœì  ëª¨ë¸ ì €ì¥ìš© -----
best_acc = 0.0
best_params = {}
results = []

# ----- ë°˜ë³µ ì‹¤í—˜ -----
for i, params in enumerate(param_grid):
    print(f"\nğŸ§ª Trial {i + 1}/{len(param_grid)} - Params: {params}")

    # ë°ì´í„°ë¡œë” ì„¤ì •
    train_loader = DataLoader(train_dataset, batch_size=params["BATCH_SIZE"], shuffle=True, num_workers=NUM_WORKERS)
    val_loader = DataLoader(val_dataset, batch_size=params["BATCH_SIZE"], shuffle=False, num_workers=NUM_WORKERS)

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = create_model('vit_base_patch32_224', pretrained=True, num_classes=NUM_CLASSES).to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=params["LR"])

    # í•™ìŠµ ë°˜ë³µ
    for epoch in range(params["EPOCHS"]):
        model.train()
        total_loss = 0.0
        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch + 1}"):
            images, labels = images.to(DEVICE), labels.to(DEVICE)

            outputs = model(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        acc = evaluate(model, val_loader)
        print(f"ğŸ“Š Epoch [{epoch + 1}/{params['EPOCHS']}], Loss: {total_loss:.4f}, Val Acc: {acc:.2f}%")

    # ê¸°ë¡ ì €ì¥
    results.append({
        "BATCH_SIZE": params["BATCH_SIZE"],
        "LR": params["LR"],
        "EPOCHS": params["EPOCHS"],
        "ACC": acc
    })

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    if acc > best_acc:
        best_acc = acc
        best_params = params
        torch.save(model.state_dict(), MODEL_PATH)
        print(f"New best model saved with acc {best_acc:.2f}% and params {best_params}")

print("\nì „ì²´ ì‹¤í—˜ ì™„ë£Œ!")
print(f"Best Accuracy: {best_acc:.2f}% with params: {best_params}")

# ----- ì‹œê°í™” -----
labels = [f"BS={r['BATCH_SIZE']}, LR={r['LR']}, EP={r['EPOCHS']}" for r in results]
accuracies = [r["ACC"] for r in results]

plt.figure(figsize=(10, 6))
plt.bar(labels, accuracies, color='skyblue')
plt.ylabel("Validation Accuracy (%)")
plt.title("ViT-B32 FFHQ - Hyperparameter Tuning Results")
plt.ylim(0, 100)
plt.xticks(rotation=15)
plt.grid(True, linestyle="--", alpha=0.5)
plt.tight_layout()
plt.show()
